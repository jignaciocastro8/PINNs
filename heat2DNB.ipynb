{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jigna\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "np.random.seed(2727)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat Equation:\n",
    "\n",
    "\\begin{align}\n",
    "\\partial_t u_{\\theta}(t,x,y) + \\partial^2_{xx}u_{\\theta}(t,x,y)+\\partial^2_{yy}u_{\\theta}(t,x,y) \n",
    "&= 0\\\\\n",
    "u_{\\theta}(0,x,y) &= -1\\\\\n",
    "u_{\\theta}(t,x,0) = u_{\\theta}(t,0,y) = u_{\\theta}(t,1,y) &= -1\\\\\n",
    "u_{\\theta}(t,x,1) &=1\n",
    "\\end{align}\n",
    "\n",
    "Here time-space is modeled by $(t,x,y)\\in[0,1]^{3}$, thus $u_{\\theta}\\colon[0,1]^3\\to \\R$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatModel(tf.Module):\n",
    "    # Heat equation PINN-solver. \n",
    "    def __init__(self, layers_size):\n",
    "\n",
    "        self.layers = layers_size\n",
    "        # List of tf.Tensor objects\n",
    "        self.W = []\n",
    "\n",
    "        # Initializer\n",
    "        init = tf.initializers.GlorotUniform(seed=333)\n",
    "\n",
    "        for i in range(len(layers_size) - 1):\n",
    "            input_dim = layers_size[i]\n",
    "            output_dim = layers_size[i + 1]\n",
    "\n",
    "            w = tf.Variable(init([output_dim, input_dim], dtype='float64'), trainable=True, name=f'w{i+1}')\n",
    "            b = tf.zeros([output_dim, 1], dtype='float64')\n",
    "            b = tf.Variable(b, trainable=True, name=f'b{i+1}')\n",
    "\n",
    "            self.W.append(w)\n",
    "            self.W.append(b)\n",
    "\n",
    "        # Learning rate\n",
    "        self.learning_rate = 0.0001\n",
    "    \n",
    "    \n",
    "\n",
    "    def evaluate(self, x):\n",
    "        \"\"\"Evaluates the NN at x.\n",
    "\n",
    "        Args:\n",
    "            x : Shape must match the NN input shape.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: u_theta(x)\n",
    "        \"\"\"\n",
    "        a = x\n",
    "        for i in range(len(self.layers) - 2):\n",
    "            z = tf.add(tf.matmul(self.W[2*i], a), self.W[2*i + 1])\n",
    "            a = tf.nn.tanh(z)\n",
    "\n",
    "        a = tf.add(tf.matmul(self.W[-2], a), self.W[-1])\n",
    "        return a\n",
    "    \n",
    "    def set_weights(self, new_weights):\n",
    "        # Setter for the parameters.\n",
    "        # Shapes must coincide.\n",
    "        for i in range(len(new_weights)):\n",
    "            self.W[i].assign(new_weights[i])\n",
    "        self.get_weights() \n",
    "\n",
    "   \n",
    "    ##################### LOSS METHODS ###########################\n",
    "\n",
    "    def initial_condition_loss(self, init_data):\n",
    "        return tf.add(self.evaluate(init_data), 1)\n",
    "        \n",
    "    def upper_boundary_loss(self, up_boundary_data):\n",
    "        return tf.add(self.evaluate(up_boundary_data), -1)\n",
    "    \n",
    "    def lower_boundary_loss(self, lower_boundary_data):\n",
    "        return tf.add(self.evaluate(lower_boundary_data), 1)\n",
    "        \n",
    "    def left_boundary_loss(self, left_boundary_data):\n",
    "        return tf.add(self.evaluate(left_boundary_data), 1)\n",
    "    \n",
    "    def right_boundary_loss(self, right_boundary_data):\n",
    "        return tf.add(self.evaluate(right_boundary_data), 1)\n",
    "\n",
    "    def physics_loss(self, interior_data):\n",
    "\n",
    "        # Error given by the PDE over data_set.\n",
    "        # We compute the first and second derivative w.r.t the NN variable.\n",
    "        # returns tf.Tensor shape=().\n",
    "        # Every derivative is reshaped to shape (1,1).\n",
    "        \n",
    "        z = tf.reshape(tf.Variable(interior_data, trainable=False), (3,1))\n",
    "        with tf.GradientTape() as tape2:\n",
    "            with tf.GradientTape() as tape1:\n",
    "                tape1.watch(z)\n",
    "                u = self.evaluate(z)\n",
    "            u_z = tape1.gradient(u, z)\n",
    "            tape2.watch(z)\n",
    "        u_zz = tape2.gradient(u_z, z)\n",
    "\n",
    "        u_t = tf.reshape(u_z[0], (1,1))\n",
    "        u_xx = tf.reshape(u_zz[1], (1,1))\n",
    "        u_yy = tf.reshape(u_zz[2], (1,1))\n",
    "\n",
    "        del tape1, tape2\n",
    "        \n",
    "        return tf.subtract(u_t, tf.add(u_xx, u_yy))\n",
    "\n",
    "\n",
    "    def total_loss(self, init_data, up_boundary_data, lower_boundary_data, left_boundary_data, right_boundary_data, interior_data):\n",
    "        # Loss computed from the PDE + loss from training data.\n",
    "        # returns: tf.Tensor shape=()\n",
    "\n",
    "        return tf.square(self.initial_condition_loss(init_data)\\\n",
    "                          + self.upper_boundary_loss(up_boundary_data)\\\n",
    "                          + self.lower_boundary_loss(lower_boundary_data)\\\n",
    "                          + self.left_boundary_loss(left_boundary_data)\\\n",
    "                          + self.right_boundary_loss(right_boundary_data)\\\n",
    "                          + self.physics_loss(interior_data))\n",
    "\n",
    "    ##################### TRAINING METHODS ###########################\n",
    "\n",
    "    def gradients(self, boundary_data, init_data, int_data):\n",
    "        # This function computes the gradient of total_loss() method\n",
    "        # w.r.t trainable_variables.\n",
    "        # Returns gradients evaluated at the current data point and\n",
    "        # trainable variable, also returns the current value of the\n",
    "        # loss function.\n",
    "        # Since self.trainable_variables is constantly being updated,\n",
    "        # the gradient is evaluated at different values of weights.\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.trainable_variables)\n",
    "            target = self.total_loss(boundary_data, init_data, int_data)\n",
    "        gradients = tape.gradient(target, self.trainable_variables)\n",
    "        return gradients, target\n",
    "\n",
    "    def apply_gradients(self, gradients_list: list):\n",
    "        \"\"\"Updates the parameters according to SGD iteration.\n",
    "\n",
    "        Args:\n",
    "            gradients_list (list): list of tf.Tensor\n",
    "        \"\"\"\n",
    "        for g, p in zip(gradients_list, self.W):\n",
    "            p.assign_sub(self.learning_rate * g)\n",
    "    \n",
    "    \n",
    "    def train(self, num_iter, num_data):\n",
    "        n = num_data        \n",
    "        init_data = [[[0],[x],[y]] for x,y in zip(np.random.uniform(0,1,n), np.random.uniform(0,1,n))]\n",
    "        up_boundary_data = [[[t],[x],[1]] for t,x in zip(np.random.uniform(0,1,n), np.random.uniform(0,1,n))]\n",
    "        lower_boundary_data = [[[t],[x],[0]] for t,x in zip(np.random.uniform(0,1,n), np.random.uniform(0,1,n))]\n",
    "        left_boundary_data = [[[t],[0],[y]] for t,y in zip(np.random.uniform(0,1,n), np.random.uniform(0,1,n))]\n",
    "        right_boundary_data = [[[t],[1],[y]] for t,y in zip(np.random.uniform(0,1,n), np.random.uniform(0,1,n))]\n",
    "        interior_data = [[[t],[x],[y]] for t,x,y in zip(np.random.uniform(0,1,n), np.random.uniform(0,1,n), np.random.uniform(0,1,n))]\n",
    "        val = []\n",
    "        for _ in tqdm(range(num_iter)):\n",
    "            j = np.random.randint(n)\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(self.W)\n",
    "                target = self.initial_condition_loss(init_data[j])\n",
    "                target = self.total_loss(init_data[j],\\\n",
    "                                    up_boundary_data[j],\\\n",
    "                                    lower_boundary_data[j],\\\n",
    "                                    left_boundary_data[j],\\\n",
    "                                    right_boundary_data[j],\\\n",
    "                                    interior_data[j])\n",
    "                \n",
    "            grads = tape.gradient(target, self.W)\n",
    "            self.apply_gradients(grads)\n",
    "            val.append(target)\n",
    "            if target >= 10e5:\n",
    "                break\n",
    "\n",
    "            return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with input dimension 3 (t,x,y) and output dimension 1.\n",
    "d = 20\n",
    "model = HeatModel([3,d,d,d,d,1])\n",
    "\n",
    "loss = model.train(10000,1000)\n",
    "\n",
    "values = list(map(lambda v: v[0][0].numpy(), loss))\n",
    "plt.plot(values)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
