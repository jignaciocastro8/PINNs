{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jigna\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "from sinPINN import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burgers Equation:\n",
    "\n",
    "\\begin{align}\n",
    "\\partial_t u_{\\theta}(t,z) + u_{\\theta}(t,z)\\partial_z u_{\\theta}(t,z) \n",
    "&= \\nu\\partial_{xx} u_{\\theta}(t,z)\\\\\n",
    "u_{\\theta}(0,z) &= -sin(\\pi z)\\\\\n",
    "u_{\\theta}(t,-1)  &= u_{\\theta}(t,1) = 0.\n",
    "\\end{align}\n",
    "\n",
    "Here times-space is modeled by $(t,z)\\in[0,1]\\times[-1,1]$, thus $u_{\\theta}\\colon[0,1]\\times[-1,1]\\to \\R$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgerModel(tf.Module):\n",
    "    # Models 1D PINN. \n",
    "    def __init__(self, layers):\n",
    "\n",
    "        self.nu = 0.001 / np.pi\n",
    "\n",
    "        self.layers = layers\n",
    "        # List of tf.Tensor objects\n",
    "        self.W = []\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            input_dim = layers[i]\n",
    "            output_dim = layers[i + 1]\n",
    "\n",
    "            w = tf.random.normal([output_dim, input_dim], 0, 1, dtype='float64')\n",
    "            w = tf.Variable(w, trainable=True, name=f'w{i+1}')\n",
    "\n",
    "            b = tf.zeros([output_dim, 1], dtype='float64')\n",
    "            b = tf.Variable(b, trainable=True, name=f'b{i+1}')\n",
    "\n",
    "            self.W.append(w)\n",
    "            self.W.append(b)\n",
    "\n",
    "        # Learning rate\n",
    "        self.rate = 0.001\n",
    "    \n",
    "    def evaluate(self, x):\n",
    "        # Computes u(x; theta)\n",
    "        a = x\n",
    "        for i in range(len(self.layers) - 2):\n",
    "            z = tf.add(tf.matmul(self.W[2*i], a), self.W[2*i + 1])\n",
    "            a = tf.nn.tanh(z)\n",
    "\n",
    "        a = tf.add(tf.matmul(self.W[-2], a), self.W[-1])\n",
    "        return a\n",
    "     \n",
    "    def rhs(self, x):\n",
    "        # Right hand side of the PDE.\n",
    "        # x: tf.Tensor\n",
    "        return 0.0\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.W\n",
    "    \n",
    "    def set_weights(self, new_weights):\n",
    "        # Setter for the parameters.\n",
    "        # Shapes must coincide.\n",
    "        for i in range(len(new_weights)):\n",
    "            self.W[i].assign(new_weights[i])\n",
    "        self.get_weights() \n",
    "\n",
    "    def reset_weights(self):\n",
    "        return None\n",
    "\n",
    "    ##################### LOSS METHODS ###########################\n",
    "\n",
    "    def physics_loss(self, data_set):\n",
    "        # Error given by the PDE over data_set.\n",
    "        # We compute first and second derivative w.r.t the NN variable.\n",
    "        # returns tf.Tensor shape=().\n",
    "        # Every derivative is reshaped to be shape=(1,1).\n",
    "\n",
    "        l = []\n",
    "        # Save the first and second derivative evaluated at each\n",
    "        # (t,z) of datas_set.\n",
    "        U = []\n",
    "        U_t = []\n",
    "        U_z =[]\n",
    "        U_zz = []\n",
    "\n",
    "        for x in data_set:\n",
    "            x = tf.reshape(tf.Variable(x, trainable=False), (2,1))\n",
    "            with tf.GradientTape() as tape2:\n",
    "                with tf.GradientTape() as tape1:\n",
    "                    tape1.watch(x)\n",
    "                    y = self.evaluate(x)\n",
    "                u_x = tape1.gradient(y, x)\n",
    "                tape2.watch(x)\n",
    "            u_xx = tape2.gradient(u_x, x)\n",
    "\n",
    "            u = y\n",
    "            u_t = tf.reshape(u_x[0], (1,1))\n",
    "            u_z = tf.reshape(u_x[1], (1,1))\n",
    "            u_zz = tf.reshape(u_xx[1], (1,1))\n",
    "            U.append(u)\n",
    "            U_t.append(u_t)\n",
    "            U_z.append(u_z)\n",
    "            U_zz.append(u_zz)\n",
    "\n",
    "            # Save residue evaluated at x.\n",
    "            aux = tf.add(u_t, tf.matmul(u, u_z))\n",
    "            l.append(tf.add(aux, tf.matmul(u_zz, [[-self.nu]])))\n",
    "            \n",
    "            del tape1, tape2\n",
    "\n",
    "\n",
    "        l = tf.reshape(l, (1,len(data_set)))\n",
    "        loss = tf.math.reduce_mean(tf.math.multiply(l, l))\n",
    "        return loss \n",
    "\n",
    "\n",
    "\n",
    "    def boundary_condition(self, boundary_data):\n",
    "        init, up, down = boundary_data\n",
    "        M = len(init)\n",
    "        #return tf.reshape(a, ())\n",
    "        I = []\n",
    "        U = []\n",
    "        D = []\n",
    "        for i, u, d in zip(init, up, down):\n",
    "            I.append(tf.subtract(self.evaluate(i), tf.math.sin(i[1])))\n",
    "            U.append(self.evaluate(u))\n",
    "            D.append(self.evaluate(d))\n",
    "\n",
    "        I = tf.reshape(I, (1,M))\n",
    "        U = tf.reshape(U, (1,M))\n",
    "        D = tf.reshape(D, (1,M))\n",
    "        lossI = tf.math.reduce_mean(tf.math.multiply(I,I))\n",
    "        lossU = tf.math.reduce_mean(tf.math.multiply(U,U))\n",
    "        lossD = tf.math.reduce_mean(tf.math.multiply(D,D))\n",
    "        \n",
    "        return tf.add(tf.add(lossI, lossU),lossD)\n",
    "\n",
    "    def total_loss(self, data_set, boundary_data):\n",
    "        # Loss computed from the PDE + loss from training data.\n",
    "        # returns tf.Tensor shape=()\n",
    "\n",
    "        return tf.add(self.physics_loss(data_set), self.boundary_condition(boundary_data))\n",
    "\n",
    "    ##################### TRAINING METHODS ###########################\n",
    "\n",
    "\n",
    "    def new_weight(self, old_W, gradients):\n",
    "        # old_W: list of tensors\n",
    "        # gradients: list of tensors\n",
    "        # Computes: theta_{k+1} = t_k - \\eta\\grad L(\\theta_k)\n",
    "        new_W = []\n",
    "        for w, grad in zip(old_W, gradients):\n",
    "            aux = w - self.rate * grad\n",
    "            new_W.append(aux)\n",
    "        return new_W\n",
    "\n",
    "    def gradients(self, data_set, boundary_data):\n",
    "        # Performs one iteration of GD.\n",
    "        # Since self.trainable_variables is constantly being updated,\n",
    "        # the gradient is evaluated at different values of weights.\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.trainable_variables)\n",
    "            target = self.total_loss(data_set, boundary_data)\n",
    "        gradients = tape.gradient(target, self.trainable_variables)\n",
    "        return gradients\n",
    "            \n",
    "    def update(self, data_set, boundary_data):\n",
    "        # Performs the update on the weights according to \n",
    "        # the gradient descent.\n",
    "        old_w = self.get_weights()\n",
    "        gradients = self.gradients(data_set, boundary_data)\n",
    "        new_W = self.new_weight(old_w, gradients)\n",
    "        self.set_weights(new_W)\n",
    "    \n",
    "    def train(self):\n",
    "        # Generates a batch at each iteration\n",
    "        N = 20\n",
    "        M = 20\n",
    "        num_iter = 1000\n",
    "\n",
    "        # For each iteration we generate a new random batch of data.\n",
    "        for _ in tqdm(range(num_iter)):\n",
    "\n",
    "            # Data set for the PDE loss.\n",
    "            T = np.random.uniform(0, 1, N)\n",
    "            Z = np.random.uniform(-1, 1, N)\n",
    "            data_set = [[[t], [z]] for t,z in zip(T,Z)]\n",
    "\n",
    "            # Data set for the boundaty condition.\n",
    "            boundary_data = []\n",
    "            init = [[[0],[x]] for x in np.random.uniform(-1,1,M)]\n",
    "            up = [[[t],[1.0]] for t in np.random.uniform(0,1,M)]\n",
    "            down = [[[t],[-1.0]] for t in np.random.uniform(0,1,M)]\n",
    "            boundary_data = [init, up, down]\n",
    "            \n",
    "            self.update(data_set, boundary_data)\n",
    "            \n",
    "    ##################################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BurgerModel([2,20,20,20,20,20,20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9983144835559046], [-0.6993173289619445]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data_set.\n",
    "N = 2\n",
    "T = np.random.uniform(0, 1, N)\n",
    "Z = np.random.uniform(-1, 1, N)\n",
    "data_set = [[[t], [z]] for t,z in zip(T,Z)]\n",
    "data_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[-0.46046696]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate() test:\n",
    "model.evaluate(data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (20, 2) name:  w1:0\n",
      "shape:  (20, 1) name:  b1:0\n",
      "shape:  (20, 20) name:  w2:0\n",
      "shape:  (20, 1) name:  b2:0\n",
      "shape:  (20, 20) name:  w3:0\n",
      "shape:  (20, 1) name:  b3:0\n",
      "shape:  (20, 20) name:  w4:0\n",
      "shape:  (20, 1) name:  b4:0\n",
      "shape:  (20, 20) name:  w5:0\n",
      "shape:  (20, 1) name:  b5:0\n",
      "shape:  (20, 20) name:  w6:0\n",
      "shape:  (20, 1) name:  b6:0\n",
      "shape:  (1, 20) name:  w7:0\n",
      "shape:  (1, 1) name:  b7:0\n"
     ]
    }
   ],
   "source": [
    "# model.get_weights() test:\n",
    "for tensor in model.get_weights():\n",
    "    print('shape: ', tensor.shape, 'name: ', tensor.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=3.344826217443172>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# physics_loss(data_set) test:\n",
    "model.physics_loss(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:51<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# model.train() test:\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.01352483]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([[0], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23560dc5b20>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = 0\n",
    "x = [[[t], [z]] for z in np.arange(-1,1,0.01)]\n",
    "y = [model.evaluate(v)[0,0].numpy() for v in x]\n",
    "plt.plot(np.arange(-1,1,0.01), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
