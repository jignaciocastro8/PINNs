{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "np.random.seed(2727)\n",
    "\"\"\"\n",
    "Todo: one class to create the nn, one class called Optimizer that recives a function and \n",
    "perfome some minimization algorithm on it and one class called HeatModel which controls\n",
    "the workflow and the interaction of the other classes.     \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, input_dim) -> None:\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def build(self):\n",
    "        nn = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(self.input_dim,)),\n",
    "            layers.Dense(32, activation=\"tanh\", kernel_initializer='he_normal'),\n",
    "            layers.Dense(32, activation=\"tanh\", kernel_initializer='he_normal'),\n",
    "            layers.Dense(1),\n",
    "        ])\n",
    "        return nn\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "class HeatModel:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    This class performes PINN-type algorithm to numerically solve 1D heat equation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim) -> None:\n",
    "        # First try: model represent the core nn.\n",
    "        self.model = Network(input_dim).build()\n",
    "\n",
    "        #self.opt = opt\n",
    "\n",
    "        # x represents the weights of the nn.\n",
    "        #self.x_train = x_train\n",
    "        # y represents the outputs of each loss associated to the pde.\n",
    "        #self.y_train = y_train\n",
    "\n",
    "    def derivatives(self, z):\n",
    "        \"\"\"computes the residue of the pinn loss [u_eqn, u_ini, u_up_bd, u_lower_bd]\n",
    "\n",
    "        Args:\n",
    "            z (tf.Tensor): shape=(num_data_sample, 2)\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape2:\n",
    "            tape2.watch(z)\n",
    "            with tf.GradientTape() as tape1:\n",
    "                tape1.watch(z)\n",
    "                u = self.model(z)\n",
    "            u_z = tape1.batch_jacobian(u, z)\n",
    "            u_t = u_z[..., 0]\n",
    "        u_zz = tape2.batch_jacobian(u_z, z)\n",
    "        u_xx = u_zz[..., 1, 1]\n",
    "\n",
    "        return u, u_t, u_xx\n",
    "    \n",
    "    @tf.function\n",
    "    def tf_evaluate(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = tf.reduce_mean(tf.keras.losses.mse(self.residue(x), y))\n",
    "        grads = tape.gradient(loss, self.model.trainable_variabels)\n",
    "        return loss, grads\n",
    "    \n",
    "\n",
    "    def callback(self, flat_weights):\n",
    "        \"\"\"Called after each iteration.\n",
    "\n",
    "        Args:\n",
    "            weights (np.array): current weight.\n",
    "        \"\"\"\n",
    "        shapes = self.model.get_weights()\n",
    "        # Cumulative sum to get the correct indexes.\n",
    "        split_ids = np.cumsum([np.prod(shape) for shape in [0] + shapes])\n",
    "        weights = [flat_weights[from_id:to_id].reshape(shape)\n",
    "            for from_id, to_id, shape in zip(split_ids[:-1], split_ids[1:], shapes) ]\n",
    "        self.model.set_weights(weights)\n",
    "\n",
    "    def fit(self):\n",
    "        # Flattened weights.\n",
    "        initial_weight = np.concatenate([w.flatten() for w in self.model.get_weights()])\n",
    "        scipy.optimize.fmin_l_bfgs_b(func=self.tf_evaluate, x0=initial_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinn = HeatModel(2)\n",
    "pinn.model(tf.zeros((10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x0000016D015B6F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x0000016D015B6F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153],\n",
       "        [-0.09977153]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinn.derivatives(tf.zeros((10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f = 2\n",
    "x_ini = 0\n",
    "t_f = 0.2\n",
    "\n",
    "# training input\n",
    "num_train_samples = 100\n",
    "tx_eqn = np.random.rand(num_train_samples, 2)\n",
    "tx_eqn[..., 1] = (x_f-x_ini)*tx_eqn[..., 1] + x_ini           \n",
    "tx_ini = np.random.rand(num_train_samples, 2)\n",
    "tx_ini[..., 0] = 0                               \n",
    "tx_ini[..., 1] = (x_f-x_ini)*tx_ini[..., 1] + x_ini           \n",
    "tx_bnd_up = np.random.rand(num_train_samples, 2)\n",
    "tx_bnd_up[..., 0] = t_f*tx_bnd_up[..., 0]               \n",
    "tx_bnd_up[..., 1] = x_f  # x = -1 or +1\n",
    "tx_bnd_down = np.random.rand(num_train_samples, 2)\n",
    "tx_bnd_down[..., 0] = t_f*tx_bnd_down[..., 0]              \n",
    "tx_bnd_down[..., 1] = x_ini  \n",
    "\n",
    "x_train = [tx_eqn, tx_ini, tx_bnd_up, tx_bnd_down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = np.zeros((num_train_samples, 1))\n",
    "y_train = [aux, init, aux, aux]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
